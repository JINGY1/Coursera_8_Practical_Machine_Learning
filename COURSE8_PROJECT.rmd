---
title: "COURSE8_PROJECT"
author: "JingYi"
date: "11/24/2019"
output:
  html_document:
    keep_md: true
---

# Introduction
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. 

In this project, data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants are used. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

The training data for this project are available here:
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here:
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

3 different prediction models, classification tree, random forest and gradien boosting method are performed to identify the most accurate and low sample error method in predicting the "classe" variable.

# Libraries
```{r library, include=TRUE}
library(ggplot2)
library(caret)
library(rpart)
library(gbm)
library(randomForest)
library(rattle)
```

# Load Data
```{r load, include=TRUE}
pml_training <- read.csv('./pml-training.csv',header = TRUE)
pml_testing <- read.csv('./pml-testing.csv',header = TRUE)
```

# Exploratory Data
```{r explore, include=TRUE}
dim(pml_training)
str(pml_training)
dim(pml_testing)
str(pml_testing)
```

After exploring the data, we found there are some variables with value NA and the first 7 columns are meaningless to the outcome.

# Data Cleaning
```{r clean1, include=TRUE}
training_col_na <- which(colSums(is.na(pml_training)|pml_training=="") > 0.9*dim(pml_training)[1])  #select columns with null or blank value which more than 90% of the observation
pml_training_cln <- pml_training[,-training_col_na]   #remove columns with NA
pml_training_cln <- pml_training_cln[,-c(1:7)]        #remove first 7 columns
dim(pml_training_cln)
```

```{r clean2, include=TRUE}
testing_col_na <- which(colSums(is.na(pml_testing)|pml_testing=="") > 0.9*dim(pml_testing)[1])
pml_testing_cln <- pml_testing[,-testing_col_na]
pml_testing_cln <- pml_testing_cln[,-c(1:7)]
dim(pml_testing_cln)
```

Both training and testing data left 53 variables from 160 variables.

# Data Preparation for Training Data
```{r prepare, include=TRUE}
set.seed(789)
partition_data <- createDataPartition(pml_training_cln$classe,p=0.75)[[1]]  #split the training data by 75%
train_data <- pml_training_cln[partition_data,]
test_data <- pml_training_cln[-partition_data,]
```

# Model Building
In this project, we will use 3 models to predict the outcome:
*1. Classification Tree
*2. Random Forest
*3. Gradient Boosting Method

All models will using Cross-validated method for resampling.

# Model 1 - Classification Tree
```{r model1, include=TRUE}
model_ct <- train(classe~., data=train_data, method="rpart", trControl=trainControl(method = "cv", number = 5))
model_ct
fancyRpartPlot(model_ct$finalModel)
pred_ct <- predict(model_ct, newdata = test_data)
confusionMatrix(test_data$classe,pred_ct)
```

From the result shows the accuracy is only 48.95% which has very high of sample error about 51%. This showing the model cannot predict the outcome very well.

# Model 2 - Random Forest
```{r model2, include=TRUE}
model_rf <- train(classe~., data=train_data, method="rf", trControl=trainControl(method = "cv", number = 5))
model_rf
pred_rf <- predict(model_rf, newdata = test_data)
confusionMatrix(test_data$classe,pred_rf)
plot(model_rf, main="Model Accuracy with Number of Predictors")
```

By using Random Forest model, the accuracy is 99.57% which is has very small error. This showing the model is good for prediction. From the result can see that using 2 predictors and 27 predictors has small effect on the accuracy. 

# Model 3 - Gradient Boosting Method
```{r model3, include=TRUE}
model_gbm <- train(classe~., data=train_data, method="gbm", trControl=trainControl(method = "cv", number = 5), verbose=FALSE)
model_gbm
pred_gbm <- predict(model_gbm, newdata = test_data)
confusionMatrix(test_data$classe,pred_gbm)
```

Third model we used is Gradient Boosting Model. This shows the accuracy is 96.47%, which is well for prediction.

# Conclusion

From the results of 3 models, we choose Random Forest Model as the best model for this data prediction. So, the prediction result as shown below:

```{r ftest, include=TRUE}
final_test <- predict(model_rf, newdata = pml_testing_cln)
final_test
```

